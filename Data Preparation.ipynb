{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "This notebook is meant to prepare the data to be used for regression analysis.<br>\n",
    "\n",
    "The following steps will be performed:<br>\n",
    "    1. Pull Divvy trip data into one DataFrame\n",
    "    2. Visualize patterns of trip frequency\n",
    "    3. Set a 'time_bucket' variable\n",
    "    4. Create a .csv of trip_data for future use\n",
    "    5. Create a DataFrame shell for aggregating trip data and weather data\n",
    "    6. Add in trip data\n",
    "    6. Add in weather data\n",
    "    7. Clean up and export to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start out by importing necessary software packages.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Divvy trip data into one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiconway\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# Column names have varied slightly over time, so we need to set them ourselves for consistency.\n",
    "columns = [\n",
    "    'trip_id',\n",
    "    'start_time',\n",
    "    'end_time',\n",
    "    'bikeid',\n",
    "    'tripduration',\n",
    "    'from_station_id',\n",
    "    'from_station_name',\n",
    "    'to_station_id',\n",
    "    'to_station_name',\n",
    "    'usertype',\n",
    "    'gender',\n",
    "    'birthyear'\n",
    "]\n",
    "\n",
    "# To ensure quality, we will specify data types.\n",
    "# Note, the birthyear has to be a float (not an int) because it can contain null values. \n",
    "data_types = {\n",
    "    'trip_id':np.int64,\n",
    "    'start_time':object,\n",
    "    'end_time':object,\n",
    "    'bikeid':np.int64,\n",
    "    'tripduration':np.int64,\n",
    "    'from_station_id':np.int64,\n",
    "    'from_station_name':object,\n",
    "    'to_station_id':np.int64,\n",
    "    'to_station_name':object,\n",
    "    'usertype':object,\n",
    "    'gender':object,\n",
    "    'birthyear':np.float64\n",
    "}\n",
    "\n",
    "# The first data file, 'Divvy_Trips_2013.csv', is omitted from the file list, as it is used to initialize the DataFrame.\n",
    "file_names = [\n",
    "    'Divvy_Trips_2014_Q1Q2.csv',\n",
    "    'Divvy_Trips_2014-Q3-07.csv',\n",
    "    'Divvy_Trips_2014-Q3-0809.csv',\n",
    "    'Divvy_Trips_2014-Q4.csv',\n",
    "    'Divvy_Trips_2015-Q1.csv',\n",
    "    'Divvy_Trips_2015-Q2.csv', \n",
    "    'Divvy_Trips_2015_07.csv',\n",
    "    'Divvy_Trips_2015_08.csv',\n",
    "    'Divvy_Trips_2015_09.csv',\n",
    "    'Divvy_Trips_2015_Q4.csv',\n",
    "    'Divvy_Trips_2016_Q1.csv',\n",
    "    'Divvy_Trips_2016_04.csv',\n",
    "    'Divvy_Trips_2016_05.csv',\n",
    "    'Divvy_Trips_2016_06.csv',\n",
    "    'Divvy_Trips_2016_Q3.csv',\n",
    "    'Divvy_Trips_2016_Q4.csv',   \n",
    "    'Divvy_Trips_2017_Q1.csv',\n",
    "    'Divvy_Trips_2017_Q2.csv',\n",
    "    'Divvy_Trips_2017_Q3.csv',\n",
    "    'Divvy_Trips_2017_Q4.csv'\n",
    "]\n",
    "\n",
    "# We initialize the DataFrame by loading in the first datafile.\n",
    "# Then we remove any duplicates.\n",
    "# Finally, we convert the start_time and end_time columns into datetimes\n",
    "raw_trip_data = pd.read_csv('./Raw_Data/Divvy/Unzipped/Trips/Divvy_Trips_2013.csv',\n",
    "                            header=0, names=columns, index_col='trip_id', dtype=data_types,\n",
    "                            parse_dates=['start_time','end_time'], infer_datetime_format=True)\n",
    "raw_trip_data = raw_trip_data.drop_duplicates(keep='first')\n",
    "\n",
    "# We iterate through the file names and append to the raw data file, again removing duplicates and converting to datetime.\n",
    "for file_name in file_names:\n",
    "    file_path = './Raw_Data/Divvy/Unzipped/Trips/'+str(file_name)\n",
    "    new_data = pd.read_csv(file_path, header=0, names=columns, index_col='trip_id', dtype=data_types,\n",
    "                          parse_dates=['start_time','end_time'], infer_datetime_format=True)\n",
    "    new_data = new_data.drop_duplicates(keep='first')\n",
    "    raw_trip_data = raw_trip_data.append(new_data, verify_integrity=True)\n",
    "\n",
    "raw_trip_data = raw_trip_data.drop_duplicates(keep='first')\n",
    "\n",
    "# We drop unnecessary columns to create the initial 'trip_data' DataFrame.\n",
    "unnecessary_columns = ['bikeid','tripduration','from_station_name','to_station_name','usertype','gender','birthyear']\n",
    "trip_data = raw_trip_data.drop(unnecessary_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We add separate columns in 'trip_data' for each unit of time that we will need.\n",
    "\n",
    "trip_data.loc[:,'start_date'] = trip_data.loc[:,'start_time'].dt.date\n",
    "trip_data.loc[:,'start_weekday'] = trip_data.loc[:,'start_time'].dt.weekday\n",
    "trip_data.loc[:,'start_hour'] = trip_data.loc[:,'start_time'].dt.hour\n",
    "\n",
    "trip_data.loc[:,'end_date'] = trip_data.loc[:,'end_time'].dt.date\n",
    "trip_data.loc[:,'end_weekday'] = trip_data.loc[:,'end_time'].dt.weekday\n",
    "trip_data.loc[:,'end_hour'] = trip_data.loc[:,'end_time'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize patterns of trip frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>start_weekday</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11594</td>\n",
       "      <td>8975</td>\n",
       "      <td>9553</td>\n",
       "      <td>10616</td>\n",
       "      <td>12795</td>\n",
       "      <td>22397</td>\n",
       "      <td>27008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6096</td>\n",
       "      <td>4592</td>\n",
       "      <td>4786</td>\n",
       "      <td>5647</td>\n",
       "      <td>7181</td>\n",
       "      <td>16325</td>\n",
       "      <td>17777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3475</td>\n",
       "      <td>2420</td>\n",
       "      <td>2450</td>\n",
       "      <td>2860</td>\n",
       "      <td>4064</td>\n",
       "      <td>10147</td>\n",
       "      <td>12030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2222</td>\n",
       "      <td>1557</td>\n",
       "      <td>1759</td>\n",
       "      <td>1816</td>\n",
       "      <td>2372</td>\n",
       "      <td>5230</td>\n",
       "      <td>6879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3210</td>\n",
       "      <td>3407</td>\n",
       "      <td>3174</td>\n",
       "      <td>3174</td>\n",
       "      <td>3490</td>\n",
       "      <td>3109</td>\n",
       "      <td>4308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16081</td>\n",
       "      <td>18972</td>\n",
       "      <td>18347</td>\n",
       "      <td>17476</td>\n",
       "      <td>16138</td>\n",
       "      <td>5064</td>\n",
       "      <td>4771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60490</td>\n",
       "      <td>69503</td>\n",
       "      <td>68590</td>\n",
       "      <td>63285</td>\n",
       "      <td>58666</td>\n",
       "      <td>11618</td>\n",
       "      <td>9871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>137481</td>\n",
       "      <td>154847</td>\n",
       "      <td>150734</td>\n",
       "      <td>140523</td>\n",
       "      <td>134921</td>\n",
       "      <td>27492</td>\n",
       "      <td>21355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>176038</td>\n",
       "      <td>194270</td>\n",
       "      <td>188089</td>\n",
       "      <td>181249</td>\n",
       "      <td>176755</td>\n",
       "      <td>53627</td>\n",
       "      <td>42142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>86213</td>\n",
       "      <td>86114</td>\n",
       "      <td>83804</td>\n",
       "      <td>84063</td>\n",
       "      <td>89430</td>\n",
       "      <td>85510</td>\n",
       "      <td>76114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>69297</td>\n",
       "      <td>61662</td>\n",
       "      <td>58075</td>\n",
       "      <td>60194</td>\n",
       "      <td>71392</td>\n",
       "      <td>120997</td>\n",
       "      <td>114629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>89361</td>\n",
       "      <td>78374</td>\n",
       "      <td>73339</td>\n",
       "      <td>76411</td>\n",
       "      <td>95387</td>\n",
       "      <td>152346</td>\n",
       "      <td>147125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>103629</td>\n",
       "      <td>89447</td>\n",
       "      <td>85772</td>\n",
       "      <td>89199</td>\n",
       "      <td>115178</td>\n",
       "      <td>175206</td>\n",
       "      <td>165817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>103479</td>\n",
       "      <td>88132</td>\n",
       "      <td>84468</td>\n",
       "      <td>88185</td>\n",
       "      <td>117272</td>\n",
       "      <td>184769</td>\n",
       "      <td>172479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100964</td>\n",
       "      <td>85284</td>\n",
       "      <td>81333</td>\n",
       "      <td>85264</td>\n",
       "      <td>116755</td>\n",
       "      <td>185873</td>\n",
       "      <td>174145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>119398</td>\n",
       "      <td>105930</td>\n",
       "      <td>101466</td>\n",
       "      <td>107285</td>\n",
       "      <td>141147</td>\n",
       "      <td>182241</td>\n",
       "      <td>176818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>189083</td>\n",
       "      <td>187006</td>\n",
       "      <td>179808</td>\n",
       "      <td>180651</td>\n",
       "      <td>201707</td>\n",
       "      <td>172881</td>\n",
       "      <td>167039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>272986</td>\n",
       "      <td>277652</td>\n",
       "      <td>262175</td>\n",
       "      <td>263084</td>\n",
       "      <td>227720</td>\n",
       "      <td>156013</td>\n",
       "      <td>148106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>179782</td>\n",
       "      <td>186313</td>\n",
       "      <td>171529</td>\n",
       "      <td>176309</td>\n",
       "      <td>146599</td>\n",
       "      <td>131113</td>\n",
       "      <td>122443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>115618</td>\n",
       "      <td>120364</td>\n",
       "      <td>110958</td>\n",
       "      <td>114537</td>\n",
       "      <td>96923</td>\n",
       "      <td>97173</td>\n",
       "      <td>92578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>75408</td>\n",
       "      <td>79595</td>\n",
       "      <td>73692</td>\n",
       "      <td>77338</td>\n",
       "      <td>65062</td>\n",
       "      <td>68641</td>\n",
       "      <td>63489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>52851</td>\n",
       "      <td>57742</td>\n",
       "      <td>53993</td>\n",
       "      <td>56228</td>\n",
       "      <td>48405</td>\n",
       "      <td>53878</td>\n",
       "      <td>46759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33056</td>\n",
       "      <td>38388</td>\n",
       "      <td>38885</td>\n",
       "      <td>40561</td>\n",
       "      <td>41035</td>\n",
       "      <td>48916</td>\n",
       "      <td>34457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17886</td>\n",
       "      <td>19659</td>\n",
       "      <td>20433</td>\n",
       "      <td>23602</td>\n",
       "      <td>32004</td>\n",
       "      <td>38002</td>\n",
       "      <td>20363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "start_weekday       0       1       2       3       4       5       6\n",
       "start_hour                                                           \n",
       "0               11594    8975    9553   10616   12795   22397   27008\n",
       "1                6096    4592    4786    5647    7181   16325   17777\n",
       "2                3475    2420    2450    2860    4064   10147   12030\n",
       "3                2222    1557    1759    1816    2372    5230    6879\n",
       "4                3210    3407    3174    3174    3490    3109    4308\n",
       "5               16081   18972   18347   17476   16138    5064    4771\n",
       "6               60490   69503   68590   63285   58666   11618    9871\n",
       "7              137481  154847  150734  140523  134921   27492   21355\n",
       "8              176038  194270  188089  181249  176755   53627   42142\n",
       "9               86213   86114   83804   84063   89430   85510   76114\n",
       "10              69297   61662   58075   60194   71392  120997  114629\n",
       "11              89361   78374   73339   76411   95387  152346  147125\n",
       "12             103629   89447   85772   89199  115178  175206  165817\n",
       "13             103479   88132   84468   88185  117272  184769  172479\n",
       "14             100964   85284   81333   85264  116755  185873  174145\n",
       "15             119398  105930  101466  107285  141147  182241  176818\n",
       "16             189083  187006  179808  180651  201707  172881  167039\n",
       "17             272986  277652  262175  263084  227720  156013  148106\n",
       "18             179782  186313  171529  176309  146599  131113  122443\n",
       "19             115618  120364  110958  114537   96923   97173   92578\n",
       "20              75408   79595   73692   77338   65062   68641   63489\n",
       "21              52851   57742   53993   56228   48405   53878   46759\n",
       "22              33056   38388   38885   40561   41035   48916   34457\n",
       "23              17886   19659   20433   23602   32004   38002   20363"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we get the count of trips by day and hour (based on start_time).\n",
    "# These results were then visually analyzed in Excel.\n",
    "pd.crosstab(trip_data.loc[:,'start_hour'], trip_data.loc[:,'start_weekday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>end_weekday</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13905</td>\n",
       "      <td>10641</td>\n",
       "      <td>11539</td>\n",
       "      <td>12344</td>\n",
       "      <td>14663</td>\n",
       "      <td>24601</td>\n",
       "      <td>30385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7114</td>\n",
       "      <td>5359</td>\n",
       "      <td>5508</td>\n",
       "      <td>6465</td>\n",
       "      <td>8104</td>\n",
       "      <td>17201</td>\n",
       "      <td>19968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4410</td>\n",
       "      <td>3030</td>\n",
       "      <td>3045</td>\n",
       "      <td>3558</td>\n",
       "      <td>4938</td>\n",
       "      <td>12083</td>\n",
       "      <td>13466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2581</td>\n",
       "      <td>1788</td>\n",
       "      <td>1936</td>\n",
       "      <td>1992</td>\n",
       "      <td>2586</td>\n",
       "      <td>6103</td>\n",
       "      <td>8261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2999</td>\n",
       "      <td>2823</td>\n",
       "      <td>2735</td>\n",
       "      <td>2759</td>\n",
       "      <td>3220</td>\n",
       "      <td>3659</td>\n",
       "      <td>4807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13155</td>\n",
       "      <td>15621</td>\n",
       "      <td>14953</td>\n",
       "      <td>14521</td>\n",
       "      <td>13377</td>\n",
       "      <td>4273</td>\n",
       "      <td>4460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50779</td>\n",
       "      <td>58326</td>\n",
       "      <td>57543</td>\n",
       "      <td>52956</td>\n",
       "      <td>49377</td>\n",
       "      <td>9812</td>\n",
       "      <td>8288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>119109</td>\n",
       "      <td>135284</td>\n",
       "      <td>132777</td>\n",
       "      <td>123268</td>\n",
       "      <td>117299</td>\n",
       "      <td>22585</td>\n",
       "      <td>16974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>178608</td>\n",
       "      <td>199030</td>\n",
       "      <td>192349</td>\n",
       "      <td>184211</td>\n",
       "      <td>178787</td>\n",
       "      <td>46640</td>\n",
       "      <td>35359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>98636</td>\n",
       "      <td>102124</td>\n",
       "      <td>99489</td>\n",
       "      <td>98812</td>\n",
       "      <td>101380</td>\n",
       "      <td>73911</td>\n",
       "      <td>63931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>65158</td>\n",
       "      <td>59563</td>\n",
       "      <td>57125</td>\n",
       "      <td>58746</td>\n",
       "      <td>67734</td>\n",
       "      <td>106971</td>\n",
       "      <td>100913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>82346</td>\n",
       "      <td>73242</td>\n",
       "      <td>68031</td>\n",
       "      <td>70484</td>\n",
       "      <td>86498</td>\n",
       "      <td>138352</td>\n",
       "      <td>134724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>101429</td>\n",
       "      <td>88711</td>\n",
       "      <td>84745</td>\n",
       "      <td>88041</td>\n",
       "      <td>111980</td>\n",
       "      <td>166484</td>\n",
       "      <td>159038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>102771</td>\n",
       "      <td>88266</td>\n",
       "      <td>84554</td>\n",
       "      <td>88291</td>\n",
       "      <td>116387</td>\n",
       "      <td>180083</td>\n",
       "      <td>168194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>99938</td>\n",
       "      <td>83281</td>\n",
       "      <td>80046</td>\n",
       "      <td>83817</td>\n",
       "      <td>114581</td>\n",
       "      <td>185098</td>\n",
       "      <td>172761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>115424</td>\n",
       "      <td>100939</td>\n",
       "      <td>96333</td>\n",
       "      <td>101571</td>\n",
       "      <td>135706</td>\n",
       "      <td>183592</td>\n",
       "      <td>177564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>170520</td>\n",
       "      <td>164370</td>\n",
       "      <td>157739</td>\n",
       "      <td>159640</td>\n",
       "      <td>186826</td>\n",
       "      <td>178738</td>\n",
       "      <td>173114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>271975</td>\n",
       "      <td>274573</td>\n",
       "      <td>261143</td>\n",
       "      <td>260577</td>\n",
       "      <td>236374</td>\n",
       "      <td>165906</td>\n",
       "      <td>158078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>199756</td>\n",
       "      <td>205748</td>\n",
       "      <td>188793</td>\n",
       "      <td>194721</td>\n",
       "      <td>161534</td>\n",
       "      <td>141984</td>\n",
       "      <td>134284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>127547</td>\n",
       "      <td>131085</td>\n",
       "      <td>121654</td>\n",
       "      <td>125569</td>\n",
       "      <td>107483</td>\n",
       "      <td>109781</td>\n",
       "      <td>103346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>83128</td>\n",
       "      <td>87720</td>\n",
       "      <td>80646</td>\n",
       "      <td>84842</td>\n",
       "      <td>71453</td>\n",
       "      <td>77388</td>\n",
       "      <td>72442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>58142</td>\n",
       "      <td>62457</td>\n",
       "      <td>57404</td>\n",
       "      <td>60269</td>\n",
       "      <td>51541</td>\n",
       "      <td>57461</td>\n",
       "      <td>51093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>36944</td>\n",
       "      <td>43036</td>\n",
       "      <td>43154</td>\n",
       "      <td>44192</td>\n",
       "      <td>42954</td>\n",
       "      <td>50676</td>\n",
       "      <td>38838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21242</td>\n",
       "      <td>23108</td>\n",
       "      <td>23944</td>\n",
       "      <td>27188</td>\n",
       "      <td>34531</td>\n",
       "      <td>41928</td>\n",
       "      <td>23469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "end_weekday       0       1       2       3       4       5       6\n",
       "end_hour                                                           \n",
       "0             13905   10641   11539   12344   14663   24601   30385\n",
       "1              7114    5359    5508    6465    8104   17201   19968\n",
       "2              4410    3030    3045    3558    4938   12083   13466\n",
       "3              2581    1788    1936    1992    2586    6103    8261\n",
       "4              2999    2823    2735    2759    3220    3659    4807\n",
       "5             13155   15621   14953   14521   13377    4273    4460\n",
       "6             50779   58326   57543   52956   49377    9812    8288\n",
       "7            119109  135284  132777  123268  117299   22585   16974\n",
       "8            178608  199030  192349  184211  178787   46640   35359\n",
       "9             98636  102124   99489   98812  101380   73911   63931\n",
       "10            65158   59563   57125   58746   67734  106971  100913\n",
       "11            82346   73242   68031   70484   86498  138352  134724\n",
       "12           101429   88711   84745   88041  111980  166484  159038\n",
       "13           102771   88266   84554   88291  116387  180083  168194\n",
       "14            99938   83281   80046   83817  114581  185098  172761\n",
       "15           115424  100939   96333  101571  135706  183592  177564\n",
       "16           170520  164370  157739  159640  186826  178738  173114\n",
       "17           271975  274573  261143  260577  236374  165906  158078\n",
       "18           199756  205748  188793  194721  161534  141984  134284\n",
       "19           127547  131085  121654  125569  107483  109781  103346\n",
       "20            83128   87720   80646   84842   71453   77388   72442\n",
       "21            58142   62457   57404   60269   51541   57461   51093\n",
       "22            36944   43036   43154   44192   42954   50676   38838\n",
       "23            21242   23108   23944   27188   34531   41928   23469"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We repeat the process using end_time to confirm that the patterns hold, which they do.\n",
    "pd.crosstab(trip_data.loc[:,'end_hour'], trip_data.loc[:,'end_weekday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Set time buckets\n",
    "\n",
    "Based on the results of the visual analysis, the following time buckets were determined:<br>\n",
    "    0. Weekday = 0-4, Hour = 0-5 (1.52% of trips)\n",
    "    1. Weekday = 0-4, Hour = 6-9 (17.26% of trips)\n",
    "    2. Weekday = 0-4, Hour = 10-15 (19.85% of trips)\n",
    "    3. Weekday = 0-4, Hour = 16-19 (26.49% of trips)\n",
    "    4. Weekday = 0-4, Hour = 20-23 (6.84% of trips)\n",
    "    5. Weekday = 5-6, Hour = 0-9 (3.35% of trips)\n",
    "    6. Weekday = 5-6, Hour = 10-18 (20.62% of trips)\n",
    "    7. Weekday = 5-6, Hour = 19-23 (4.08% of trips)\n",
    "\n",
    "Notes:<br>\n",
    "Percentages based on start_time (similar results for end_time).<br>\n",
    "See supporting workfile 'Trips by Weekday and Hour.xlsx' for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We define a function to set the time bucket for the start_time, then use .apply() to add it to the data.\n",
    "def set_start_time_bucket(row):\n",
    "    if row.loc['start_weekday'] <= 4:\n",
    "        if row.loc['start_hour'] < 6:\n",
    "            return 0\n",
    "        elif row.loc['start_hour'] < 10:\n",
    "            return 1\n",
    "        elif row.loc['start_hour'] < 16:\n",
    "            return 2\n",
    "        elif row.loc['start_hour'] < 20:\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "    else:\n",
    "        if row.loc['start_hour'] < 10:\n",
    "            return 5\n",
    "        elif row.loc['start_hour'] < 19:\n",
    "            return 6\n",
    "        else:\n",
    "            return 7\n",
    "\n",
    "trip_data.loc[:,'start_time_bucket'] = trip_data.apply(set_start_time_bucket, axis=1)\n",
    "\n",
    "# We do the same process for end_time.\n",
    "def set_end_time_bucket(row):\n",
    "    if row.loc['end_weekday'] <= 4:\n",
    "        if row.loc['end_hour'] < 6:\n",
    "            return 0\n",
    "        elif row.loc['end_hour'] < 10:\n",
    "            return 1\n",
    "        elif row.loc['end_hour'] < 16:\n",
    "            return 2\n",
    "        elif row.loc['end_hour'] < 20:\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "    else:\n",
    "        if row.loc['end_hour'] < 10:\n",
    "            return 5\n",
    "        elif row.loc['end_hour'] < 19:\n",
    "            return 6\n",
    "        else:\n",
    "            return 7\n",
    "\n",
    "trip_data.loc[:,'end_time_bucket'] = trip_data.apply(set_end_time_bucket, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a csv of trip_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We create a text 'tag' that aggregates station ID, date, and time bucket.\n",
    "trip_data.loc[:,'start_tag'] = 'ID' + trip_data.loc[:,'from_station_id'].astype(str) + 'Date' + trip_data.loc[:,'start_date'].astype(str) + 'Time' + trip_data.loc[:,'start_time_bucket'].astype(str)\n",
    "trip_data.loc[:,'end_tag'] = 'ID' + trip_data.loc[:,'to_station_id'].astype(str) + 'Date' + trip_data.loc[:,'end_date'].astype(str) + 'Time' + trip_data.loc[:,'end_time_bucket'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start_time           datetime64[ns]\n",
       "end_time             datetime64[ns]\n",
       "from_station_id               int64\n",
       "to_station_id                 int64\n",
       "start_date                   object\n",
       "start_weekday                 int64\n",
       "start_hour                    int64\n",
       "end_date                     object\n",
       "end_weekday                   int64\n",
       "end_hour                      int64\n",
       "start_time_bucket             int64\n",
       "end_time_bucket               int64\n",
       "start_tag                    object\n",
       "end_tag                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are going to create a csv of the trip_data so that we can avoid running the cells above again if the kernel restarts.\n",
    "# We need the data types to turn the csv back into a DataFrame.\n",
    "trip_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We create the csv of trip_data to call back later.\n",
    "trip_data.to_csv('./Supporting_Workfiles/trip_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiconway\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# We call back the trip_data csv.\n",
    "# If the kernel restarts, RUN THIS CELL FIRST, DISREGARD CELLS ABOVE (except for the initial cell to import packages).\n",
    "columns = [\n",
    "    'trip_id',\n",
    "    'start_time',\n",
    "    'end_time',\n",
    "    'from_station_id',\n",
    "    'to_station_id',\n",
    "    'start_date',\n",
    "    'start_weekday',\n",
    "    'start_hour',\n",
    "    'end_date',\n",
    "    'end_weekday',\n",
    "    'end_hour',\n",
    "    'start_time_bucket',\n",
    "    'end_time_bucket',\n",
    "    'start_tag',\n",
    "    'end_tag'\n",
    "]\n",
    "\n",
    "data_types = {\n",
    "    'trip_id':np.int64,\n",
    "    'start_time':object,\n",
    "    'end_time':object,\n",
    "    'from_station_id':np.int64,\n",
    "    'to_station_id':np.int64,\n",
    "    'start_date':object,\n",
    "    'start_weekday':np.int64,\n",
    "    'start_hour':np.int64,\n",
    "    'end_date':object,\n",
    "    'end_weekday':np.int64,\n",
    "    'end_hour':np.int64,\n",
    "    'start_time_bucket':np.int64,\n",
    "    'end_time_bucket':np.int64,\n",
    "    'start_tag':object,\n",
    "    'end_tag':object\n",
    "}\n",
    "\n",
    "trip_data = pd.read_csv('./Supporting_Workfiles/trip_data.csv',\n",
    "                            header=0, names=columns, index_col='trip_id', dtype=data_types,\n",
    "                            parse_dates=['start_time','end_time'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataFrame shell for aggregating trip data and weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need some information about the stations to combine with data provided by Divvy in Excel.\n",
    "\n",
    "unique_stations = pd.unique(np.append(pd.unique(trip_data.loc[:,'from_station_id']),pd.unique(trip_data.loc[:,'to_station_id'])))\n",
    "\n",
    "temp_list = []\n",
    "for station in unique_stations:\n",
    "    start_filter = trip_data.loc[:,'from_station_id'] == station\n",
    "    end_filter = trip_data.loc[:,'to_station_id'] == station\n",
    "    start_count = start_filter.sum()\n",
    "    end_count = end_filter.sum()\n",
    "    start_min = trip_data.loc[start_filter,'start_time'].min()\n",
    "    end_min = trip_data.loc[end_filter,'end_time'].min()\n",
    "    start_max = trip_data.loc[start_filter,'start_time'].max()\n",
    "    end_max = trip_data.loc[end_filter,'end_time'].max()\n",
    "    temp_list.append((station, start_count, end_count, start_min, end_min, start_max, end_max))\n",
    "\n",
    "column_list = ['station_id', 'start_count', 'end_count', 'start_min', 'end_min', 'start_max', 'end_max']\n",
    "station_data = pd.DataFrame(temp_list, columns=column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will send this to csv for use in Excel.\n",
    "station_data.to_csv('./Supporting_Workfiles/initial_station_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See supporting workfile 'Station Analysis.xlsx' for details on how the Divvy-provided data was worked in.<br>\n",
    "\n",
    "The 565 stations included for the remainder of the analysis were selected as follows:<br>\n",
    "    1. Active as of the 2017 Q3/Q4 data\n",
    "    2. Active since at least 2016 to ensure sufficient quantity of data\n",
    "    3. Bike capacity greater than zero\n",
    "    4. Not located in Oak Park (discontinuing Divvy operations in 2018)\n",
    "    \n",
    "We may now read back in the station data.<br>\n",
    "\n",
    "**If the kernel has restarted, you may omit running the cells above in this section (beginning at \"Create a DataFrame shell for aggregating trip data and weather data\") and skip to the cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'id',\n",
    "    'name',\n",
    "    'city',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'dpcapacity',\n",
    "    'online_date',\n",
    "    'start_count',\n",
    "    'end_count',\n",
    "    'start_min',\n",
    "    'end_min',\n",
    "    'start_max',\n",
    "    'end_max',\n",
    "    'first_day_operational'\n",
    "]\n",
    "\n",
    "data_types = {\n",
    "    'id':np.int64,\n",
    "    'name':object,\n",
    "    'city':object,\n",
    "    'latitude':np.float64,\n",
    "    'longitude':np.float64,\n",
    "    'dpcapacity':np.int64,\n",
    "    'online_date':object,\n",
    "    'start_count':np.int64,\n",
    "    'end_count':np.int64,\n",
    "    'start_min':object,\n",
    "    'end_min':object,\n",
    "    'start_max':object,\n",
    "    'end_max':object,\n",
    "    'first_day_operational':object\n",
    "}\n",
    "\n",
    "final_station_data = pd.read_csv('./Supporting_Workfiles/final_station_data.csv',\n",
    "                            header=0, names=columns, index_col='id', dtype=data_types,\n",
    "                            parse_dates=['online_date','start_min','end_min','start_max','end_max','first_day_operational'],\n",
    "                            infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now begin creation of the final data file.<br>\n",
    "\n",
    "We will generate one line, per station, per time bucket, for each day since the station went operational.<br>\n",
    "\n",
    "It is important to generate the list like this because some stations will not have any trips starting and ending in every possible time bucket. It is important to capture those \"zeroes\" in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_list=[]\n",
    "for station in final_station_data.index.values:\n",
    "    start_date = final_station_data.loc[station,'first_day_operational']\n",
    "    for date in pd.date_range(start_date, '2017-12-31'):\n",
    "        if date.weekday() <= 4:\n",
    "            for time in range(5):\n",
    "                tag = 'ID'+str(station)+'Date'+str(date.date())+'Time'+str(time)\n",
    "                temp_list.append((station, date, time, tag))\n",
    "        else:\n",
    "            for time in range(5,8):\n",
    "                tag = 'ID'+str(station)+'Date'+str(date.date())+'Time'+str(time)\n",
    "                temp_list.append((station, date, time, tag))\n",
    "\n",
    "column_list = ['station', 'date', 'time', 'tag']\n",
    "final_data = pd.DataFrame(temp_list, columns=column_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in trip data\n",
    "\n",
    "We create DataFrames from the value_counts of the tags from the trip_data, then merge those columns into the final_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_tag_counts = trip_data.loc[:,'start_tag'].value_counts().to_frame('start_tag_count')\n",
    "end_tag_counts = trip_data.loc[:,'end_tag'].value_counts().to_frame('end_tag_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_data = final_data.merge(start_tag_counts, how='left', left_on='tag', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_data = final_data.merge(end_tag_counts, how='left', left_on='tag', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Having merged in the counts, we now do general cleanup to the dataset to make it ready for use.\n",
    "\n",
    "final_data.loc[:,'start_tag_count'] = final_data.loc[:,'start_tag_count'].fillna(0)\n",
    "final_data.loc[:,'end_tag_count'] = final_data.loc[:,'end_tag_count'].fillna(0)\n",
    "\n",
    "final_data.loc[:,'start_tag_count'] = final_data.loc[:,'start_tag_count'].astype(np.int64)\n",
    "final_data.loc[:,'end_tag_count'] = final_data.loc[:,'end_tag_count'].astype(np.int64)\n",
    "\n",
    "final_data.loc[:,'bike_differential'] = final_data.loc[:,'end_tag_count'] - final_data.loc[:,'start_tag_count']\n",
    "\n",
    "final_data = final_data.set_index('tag', drop=True, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>start_tag_count</th>\n",
       "      <th>end_tag_count</th>\n",
       "      <th>bike_differential</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID2Date2015-05-09Time5</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-09</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID2Date2015-05-09Time6</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-09</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "      <td>43</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID2Date2015-05-09Time7</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-09</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID2Date2015-05-10Time5</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID2Date2015-05-10Time6</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-10</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        station       date  time  start_tag_count  \\\n",
       "tag                                                                 \n",
       "ID2Date2015-05-09Time5        2 2015-05-09     5                0   \n",
       "ID2Date2015-05-09Time6        2 2015-05-09     6               48   \n",
       "ID2Date2015-05-09Time7        2 2015-05-09     7                1   \n",
       "ID2Date2015-05-10Time5        2 2015-05-10     5                2   \n",
       "ID2Date2015-05-10Time6        2 2015-05-10     6               27   \n",
       "\n",
       "                        end_tag_count  bike_differential  \n",
       "tag                                                       \n",
       "ID2Date2015-05-09Time5              0                  0  \n",
       "ID2Date2015-05-09Time6             43                 -5  \n",
       "ID2Date2015-05-09Time7              1                  0  \n",
       "ID2Date2015-05-10Time5              2                  0  \n",
       "ID2Date2015-05-10Time6             26                 -1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in weather data\n",
    "\n",
    "Weather data csv's were prepared in Excel to be read in.<br>\n",
    "See supporting workfiles 'Hourly_Weather_Data.xlsx' and 'Daily_Weather_Normals.xlsx'.<br>\n",
    "The NOAA documentation has been saved with the supporting workfiles in pdf form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First we need to create a day_of_year tag for the daily normal weather and a date_and_time tag for the hourly weather.\n",
    "final_data.loc[:,'day_of_year'] = final_data.loc[:,'date'].dt.month.astype(str) + '-' + final_data.loc[:,'date'].dt.day.astype(str)\n",
    "final_data.loc[:,'date_and_time'] = final_data.loc[:,'date'].dt.date.astype(str) + 'Time' + final_data.loc[:,'time'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next we load in the daily normal weather data.\n",
    "\n",
    "columns = [\n",
    "    'day_of_year',\n",
    "    'normal_temp_range',\n",
    "    'normal_temp_ave',\n",
    "    'normal_temp_max',\n",
    "    'normal_temp_min'\n",
    "]\n",
    "\n",
    "data_types = {\n",
    "    'day_of_year':object,\n",
    "    'normal_temp_range':np.float64,\n",
    "    'normal_temp_ave':np.float64,\n",
    "    'normal_temp_max':np.float64,\n",
    "    'normal_temp_min':np.float64\n",
    "}\n",
    "\n",
    "daily_weather_normals = pd.read_csv('./Supporting_Workfiles/Daily_Weather_Normals.csv',\n",
    "                            header=0, names=columns, index_col='day_of_year', dtype=data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge in the daily normal weather data.\n",
    "final_data = final_data.merge(daily_weather_normals, how='left', left_on='day_of_year', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next we load in the current weather data for each time bucket.\n",
    "\n",
    "columns = [\n",
    "    'date_and_time',\n",
    "    'current_temp',\n",
    "    'current_dew_point',\n",
    "    'current_humidity',\n",
    "    'current_wind_speed',\n",
    "    'current_pressure',\n",
    "    'current_precipitation'\n",
    "]\n",
    "\n",
    "data_types = {\n",
    "    'date_and_time':object,\n",
    "    'current_temp':np.float64,\n",
    "    'current_dew_point':np.float64,\n",
    "    'current_humidity':np.float64,\n",
    "    'current_wind_speed':np.float64,\n",
    "    'current_pressure':np.float64,\n",
    "    'current_precipitation':np.float64\n",
    "}\n",
    "\n",
    "current_weather_data = pd.read_csv('./Supporting_Workfiles/Hourly_Weather_Data.csv',\n",
    "                            header=0, names=columns, index_col='date_and_time', dtype=data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge in the current weather data.\n",
    "final_data = final_data.merge(current_weather_data, how='left', left_on='date_and_time', right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up and export to .csv\n",
    "\n",
    "The final data file will be called divvy_data.<br>\n",
    "The only changes to make before exporting are to add in any additional formula-based columns and drop unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding in a total_activity column, the sum of rides beginning and ending at the station.\n",
    "final_data.loc[:,'total_activity'] = final_data.loc[:,'start_tag_count'] + final_data.loc[:,'end_tag_count']\n",
    "\n",
    "# Dropping unnecessary 'tag' columns used for merges.\n",
    "divvy_data = final_data.drop(['day_of_year', 'date_and_time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finally, we export the csv file to be used in the analysis.\n",
    "divvy_data.to_csv('./Supporting_Workfiles/divvy_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
